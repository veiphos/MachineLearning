{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAM Detection - The Naive Bayes Algorithm in Python with Scikit-Learn \n",
    "D. Shahrokhian\n",
    "https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>Taipei Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>Macao Taiwan Shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>Japan Sapporo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>Sapporo Osaka Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>Chinese Beijing Chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                  message\n",
       "0   yes            Taipei Taiwan\n",
       "1   yes    Macao Taiwan Shanghai\n",
       "2    no            Japan Sapporo\n",
       "3    no     Sapporo Osaka Taiwan\n",
       "4   yes  Chinese Beijing Chinese"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# SMS Spam Collection Data Set\n",
    "# https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "df = pd.read_table('tabla5.txt',  \n",
    "                   sep='\\t', \n",
    "                   header=None,\n",
    "                   names=['label', 'message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>taipei taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>macao taiwan shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>japan sapporo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sapporo osaka taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>chinese beijing chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                  message\n",
       "0      0            taipei taiwan\n",
       "1      0    macao taiwan shanghai\n",
       "2      1            japan sapporo\n",
       "3      1     sapporo osaka taiwan\n",
       "4      0  chinese beijing chinese"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'yes': 0, 'no': 1})\n",
    "df['message'] = df.message.map(lambda x: x.lower())\n",
    "df['message'] = df.message.str.replace('[^\\w\\s]', '')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vsmurilloso\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[taipei, taiwan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[macao, taiwan, shanghai]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[japan, sapporo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[sapporo, osaka, taiwan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[chinese, beijing, chinese]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                      message\n",
       "0      0             [taipei, taiwan]\n",
       "1      0    [macao, taiwan, shanghai]\n",
       "2      1             [japan, sapporo]\n",
       "3      1     [sapporo, osaka, taiwan]\n",
       "4      0  [chinese, beijing, chinese]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/ Natural Language Toolkit\n",
    "# Punkt Sentence Tokenizer https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df['message'] = df['message'].apply(nltk.word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[taipei, taiwan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[macao, taiwan, shanghai]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[japan, sapporo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[sapporo, osaka, taiwan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[chines, beij, chines]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                    message\n",
       "0      0           [taipei, taiwan]\n",
       "1      0  [macao, taiwan, shanghai]\n",
       "2      1           [japan, sapporo]\n",
       "3      1   [sapporo, osaka, taiwan]\n",
       "4      0     [chines, beij, chines]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.html\n",
    "#https://tartarus.org/martin/PorterStemmer/\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "df['message'] = df['message'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>taipei taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>macao taiwan shanghai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>japan sapporo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>sapporo osaka taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>chinese beijing chinese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                  message\n",
       "0      0            taipei taiwan\n",
       "1      0    macao taiwan shanghai\n",
       "2      1            japan sapporo\n",
       "3      1     sapporo osaka taiwan\n",
       "4      0  chinese beijing chinese"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "df['message'] = df['message'].apply(lambda x: ' '.join(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t1\n",
      "  (0, 7)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 2)\t1\n",
      "  (3, 4)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 8)\t1\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t2\n",
      "  (5, 1)\t2\n",
      "  (5, 6)\t1\n",
      "  (6, 1)\t1\n",
      "  (6, 3)\t1\n",
      "  (7, 9)\t1\n",
      "  (7, 1)\t1\n",
      "  (7, 2)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts = count_vect.fit_transform(df['message'])  \n",
    "print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69) \n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "print(np.mean(predicted == y_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "average perfromance\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "0.5\n",
      "[[1 1]\n",
      " [0 0]]\n",
      "0.5\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "0.5\n",
      "[[1 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [2 0]]\n",
      "1.0\n",
      "[[2]]\n",
      "1.0\n",
      "[[1 0]\n",
      " [0 1]]\n",
      "1.0\n",
      "[[2]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [2 0]]\n",
      "average perfromance\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.2) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[[2 0]\n",
      " [2 0]]\n",
      "0.75\n",
      "[[2 0]\n",
      " [1 1]]\n",
      "0.75\n",
      "[[3 0]\n",
      " [1 0]]\n",
      "0.5\n",
      "[[2 1]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[3 0]\n",
      " [0 1]]\n",
      "1.0\n",
      "[[3 0]\n",
      " [0 1]]\n",
      "0.75\n",
      "[[3 0]\n",
      " [1 0]]\n",
      "0.0\n",
      "[[0 4]\n",
      " [0 0]]\n",
      "0.75\n",
      "[[2 0]\n",
      " [1 1]]\n",
      "1.0\n",
      "[[3 0]\n",
      " [0 1]]\n",
      "average perfromance\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.5) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
