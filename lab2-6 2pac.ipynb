{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAM Detection - The Naive Bayes Algorithm in Python with Scikit-Learn \n",
    "D. Shahrokhian\n",
    "https://stackabuse.com/the-naive-bayes-algorithm-in-python-with-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggie_df = pd.read_csv('./biggie_lyrics.csv', usecols=[1], encoding='latin-1', header=None)\n",
    "biggie_df.columns = [\"lyrics\"]\n",
    "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
    "biggie_df[\"lyrics\"] = biggie_df[\"lyrics\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relax and take notes while i take tokes of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>good evenin ladies and gentlemen\\nhows everybo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>who shot ya\\nseperate the weak from the obsole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>when i die fuck it i wanna go to hell\\ncause i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>when the lala hits ya lyrics just splits ya\\nh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               lyrics\n",
       "11  relax and take notes while i take tokes of the...\n",
       "12  good evenin ladies and gentlemen\\nhows everybo...\n",
       "13  who shot ya\\nseperate the weak from the obsole...\n",
       "14  when i die fuck it i wanna go to hell\\ncause i...\n",
       "15  when the lala hits ya lyrics just splits ya\\nh..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biggie_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_df = pd.read_csv('./2pac_lyrics.csv', usecols=[1], encoding='latin-1', header=None)\n",
    "pac_df.columns = [\"lyrics\"]\n",
    "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.replace('[^\\w\\s]','')\n",
    "pac_df[\"lyrics\"] = pac_df[\"lyrics\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>little something for my godson elijah\\nand a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yo mo bee mayn drop that shit\\nyou know what t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rest in peace to my motherfucker biggy smallz\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>makaveli in this killuminati\\nall through your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>its just me against the world\\nnothin to lose\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics\n",
       "0  little something for my godson elijah\\nand a l...\n",
       "1  yo mo bee mayn drop that shit\\nyou know what t...\n",
       "2  rest in peace to my motherfucker biggy smallz\\...\n",
       "3  makaveli in this killuminati\\nall through your...\n",
       "4  its just me against the world\\nnothin to lose\\..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggie_lyrics = biggie_df[\"lyrics\"].values\n",
    "biggie_lyrics = [ song.split('\\n') for song in biggie_lyrics]\n",
    "biggie_lyrics = [line for song in biggie_lyrics for line in song]\n",
    "pac_lyrics = pac_df[\"lyrics\"].values\n",
    "pac_lyrics = [ song.split('\\n') for song in pac_lyrics]\n",
    "pac_lyrics = [line for song in pac_lyrics for line in song]\n",
    "\n",
    "rap_lines = [] \n",
    "\n",
    "for line in biggie_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([0,str(line)]))\n",
    "        \n",
    "for line in pac_lyrics:\n",
    "    if len(line.split()) > 3:\n",
    "        rap_lines.append(np.array([1,str(line)]))\n",
    "        \n",
    "rap_lines = np.array(rap_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rap_lines = pd.DataFrame(rap_lines)\n",
    "rap_lines.columns = [\"label\",\"line\"]\n",
    "rap_lines.head()\n",
    "rap_lines['label'] = rap_lines['label'].replace(['0','1'],[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[fuck, all, you, hoes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[get, a, grip, motherfucker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[yeah, this, album, is, dedicated, to, all, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[id, never, amount, to, nothin, to, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[buildings, that, i, was, hustlin, in, front, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               line\n",
       "0      0                             [fuck, all, you, hoes]\n",
       "1      0                       [get, a, grip, motherfucker]\n",
       "2      0  [yeah, this, album, is, dedicated, to, all, th...\n",
       "3      0  [id, never, amount, to, nothin, to, all, the, ...\n",
       "4      0  [buildings, that, i, was, hustlin, in, front, ..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/ Natural Language Toolkit\n",
    "# Punkt Sentence Tokenizer https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "rap_lines['line'] = rap_lines['line'].apply(nltk.word_tokenize)\n",
    "rap_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[fuck, all, you, hoe]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[get, a, grip, motherfuck]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[yeah, thi, album, is, dedic, to, all, the, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[id, never, amount, to, nothin, to, all, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[build, that, i, wa, hustlin, in, front, of, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               line\n",
       "0      0                              [fuck, all, you, hoe]\n",
       "1      0                         [get, a, grip, motherfuck]\n",
       "2      0  [yeah, thi, album, is, dedic, to, all, the, te...\n",
       "3      0  [id, never, amount, to, nothin, to, all, the, ...\n",
       "4      0  [build, that, i, wa, hustlin, in, front, of, t..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.nltk.org/api/nltk.stem.html\n",
    "#https://tartarus.org/martin/PorterStemmer/\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "rap_lines['line'] = rap_lines['line'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "rap_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f u c k   a l l   y o u   h o e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>g e t   a   g r i p   m o t h e r f u c k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>y e a h   t h i   a l b u m   i s   d e d i c ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>i d   n e v e r   a m o u n t   t o   n o t h ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>b u i l d   t h a t   i   w a   h u s t l i n ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               line\n",
       "0      0                    f u c k   a l l   y o u   h o e\n",
       "1      0          g e t   a   g r i p   m o t h e r f u c k\n",
       "2      0  y e a h   t h i   a l b u m   i s   d e d i c ...\n",
       "3      0  i d   n e v e r   a m o u n t   t o   n o t h ...\n",
       "4      0  b u i l d   t h a t   i   w a   h u s t l i n ..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts the list of words into space-separated strings\n",
    "rap_lines['line'] = rap_lines['line'].apply(lambda x: ' '.join(x))\n",
    "rap_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t1\n",
      "  (0, 17)\t1\n",
      "  (0, 24)\t2\n",
      "  (0, 34)\t1\n",
      "  (0, 21)\t2\n",
      "  (0, 10)\t1\n",
      "  (0, 20)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 30)\t2\n",
      "  (0, 15)\t1\n",
      "  (1, 22)\t1\n",
      "  (1, 25)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 27)\t2\n",
      "  (1, 29)\t2\n",
      "  (1, 16)\t2\n",
      "  (1, 14)\t2\n",
      "  (1, 17)\t1\n",
      "  (1, 24)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 30)\t1\n",
      "  (1, 15)\t1\n",
      "  (2, 13)\t3\n",
      "  :\t:\n",
      "  (1968, 24)\t5\n",
      "  (1968, 34)\t1\n",
      "  (1968, 21)\t1\n",
      "  (1968, 10)\t8\n",
      "  (1968, 20)\t2\n",
      "  (1968, 12)\t2\n",
      "  (1968, 15)\t1\n",
      "  (1969, 32)\t2\n",
      "  (1969, 23)\t1\n",
      "  (1969, 13)\t1\n",
      "  (1969, 28)\t1\n",
      "  (1969, 22)\t1\n",
      "  (1969, 25)\t1\n",
      "  (1969, 18)\t3\n",
      "  (1969, 27)\t2\n",
      "  (1969, 29)\t3\n",
      "  (1969, 14)\t4\n",
      "  (1969, 17)\t3\n",
      "  (1969, 24)\t1\n",
      "  (1969, 34)\t1\n",
      "  (1969, 21)\t1\n",
      "  (1969, 10)\t2\n",
      "  (1969, 20)\t1\n",
      "  (1969, 12)\t2\n",
      "  (1969, 30)\t1\n"
     ]
    }
   ],
   "source": [
    "# Convert a collection of text documents to a matrix of token counts\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "# to allow one letter words count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\") \n",
    "counts = count_vect.fit_transform(rap_lines['line'])  \n",
    "print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970, 36)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5380710659898477\n",
      "[[28 67]\n",
      " [24 78]]\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/28064634/random-state-pseudo-random-numberin-scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines['label'], test_size=0.1, random_state=69) \n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "import numpy as np\n",
    "predicted = model.predict(X_test)\n",
    "print(np.mean(predicted == y_test))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "1.0\n",
      "[[1]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "0.0\n",
      "[[0 0]\n",
      " [1 0]]\n",
      "average perfromance\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6040609137055838\n",
      "[[ 68 105]\n",
      " [ 51 170]]\n",
      "0.6065989847715736\n",
      "[[ 66 106]\n",
      " [ 49 173]]\n",
      "0.5989847715736041\n",
      "[[ 60 128]\n",
      " [ 30 176]]\n",
      "0.6015228426395939\n",
      "[[ 75 103]\n",
      " [ 54 162]]\n",
      "0.6192893401015228\n",
      "[[ 61 115]\n",
      " [ 35 183]]\n",
      "0.6142131979695431\n",
      "[[ 73  97]\n",
      " [ 55 169]]\n",
      "0.5913705583756346\n",
      "[[ 61 121]\n",
      " [ 40 172]]\n",
      "0.5964467005076142\n",
      "[[ 68 110]\n",
      " [ 49 167]]\n",
      "0.5862944162436549\n",
      "[[ 70 111]\n",
      " [ 52 161]]\n",
      "0.5786802030456852\n",
      "[[ 57 112]\n",
      " [ 54 171]]\n",
      "average perfromance\n",
      "0.5997461928934011\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines['label'], test_size=0.2) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601015228426396\n",
      "[[169 267]\n",
      " [126 423]]\n",
      "0.5908629441624366\n",
      "[[172 257]\n",
      " [146 410]]\n",
      "0.5766497461928934\n",
      "[[138 306]\n",
      " [111 430]]\n",
      "0.5857868020304569\n",
      "[[175 247]\n",
      " [161 402]]\n",
      "0.6081218274111675\n",
      "[[173 256]\n",
      " [130 426]]\n",
      "0.5685279187817259\n",
      "[[116 328]\n",
      " [ 97 444]]\n",
      "0.5959390862944163\n",
      "[[161 272]\n",
      " [126 426]]\n",
      "0.6131979695431472\n",
      "[[164 264]\n",
      " [117 440]]\n",
      "0.5766497461928934\n",
      "[[163 264]\n",
      " [153 405]]\n",
      "0.5918781725888325\n",
      "[[167 259]\n",
      " [143 416]]\n",
      "average perfromance\n",
      "0.5908629441624366\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for i in range(0,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(counts, rap_lines['label'], test_size=0.5) \n",
    "    model = BernoulliNB().fit(X_train, y_train)  \n",
    "\n",
    "    import numpy as np\n",
    "    predicted = model.predict(X_test)\n",
    "    print(np.mean(predicted == y_test))\n",
    "    per += np.mean(predicted == y_test)\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print(confusion_matrix(y_test, predicted))\n",
    "\n",
    "print \"average perfromance\"\n",
    "print per/10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
